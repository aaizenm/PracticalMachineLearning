## Backgrownd

For this assignment, I build a predictive model to determine whether a particular form of exercise (barbell lifting) 
is performed correctly, using accelerometer data.

## Loading of the packages
The first part is the declaration of the package which will be used. 

Note : to be reproductible, I also set the seed value.

```{r}
library(caret)
library(randomForest)
library(Hmisc)
library(corrplot)

set.seed(1234)
```
## Reading of the Data

We begin by reading in the training and testing datasets, 
assigning missing values to entries that are currently 'NA' or blank.
(commands are commented to limit the output size. You can run it deleting the "#" ) 

```{r}
#getwd()
setwd("C:/PredictiveAnalysis/R")

train <- read.csv("./data/pml-training.csv", header = TRUE, na.strings = c("NA", ""))
test <- read.csv("./data/pml-testing.csv", header = TRUE, na.strings = c("NA", ""))

```
#dim(test)
#names(train)

dim(train)

## Cleaning the data

We see that the training set consists of 19622 observations of 160 variables
```{r}
sum(complete.cases(train))
#head(train)
```

The discussion here is choosing between:
Or discarding most of the observations but using more predictors 
Or discarding some predictors to keep most of the observations.
The conclusion is that more observations is better, while additional variables may or may not helping us.

```{r}
Columns in the orignal training and testing datasets that are mostly filled with missing values are removed. 

# colSums(is.na(train))   ## This will give us which columns have 0 values
# colSums(is.na(train))==0  ## will give us a set of FALSE and TRUE values 

newtrain<- train[,colSums(is.na(train))==0]
newtest<- test[,colSums(is.na(test))==0]
dim(newtrain)
```

As we see we have eliminated 2/3 of the columns. 60 columns.

#head(newtrain)

Some of the variables in this new data set do not come from accelerometer measurements and record experimental
setup or participants' data.

So the following variables will be take out as well: 
X, user_name, raw_timestamp_part_1, raw_timestamp_part_2, cvtd_timestamp, new_window and num_window.

```{r}
todelete_cols <- grepl("X|user_name|new_window|num_window|raw_timestamp_part_1|raw_timestamp_part_2|cvtd_timestamp", colnames(newtrain))
finaltrain <- newtrai[, !todelete_cols]
finaltrain <- newtrain[, !todelete_cols]
#names(finaltrain)

Now we have 53 columns to work with.
```
dim(finaltrain)

## Spliting the data for validation purposes

Now we will split the final training dataset into a training (70% of the observations) and a validation 
(30% of the observations). 

This validation dataset will allow us to perform cross validation for developing/testing our model.


```{r}
inTrain = createDataPartition(y = finaltrain$classe, p = 0.7, list = FALSE)
finaltrain_train = finaltrain[inTrain, ]
finaltrain_valid = finaltrain[-inTrain, ]
```

## Understanding the Correlations between variables

We begin by looking at the correlations between the variables in our dataset. 
We may want to remove highly correlated predictors from our analysis and replace them with weighted 
combinations of predictors. 

The goal of your project is to predict the manner in which they did the exercise. 
This is the "classe" variable in the training set. 

```{r}
correlMatrix <- cor(finaltrain_train[, -53])
corrplot(correlMatrix, order = "FPC", method = "circle", type = "lower", tl.cex = 0.8,  tl.col = rgb(0, 0, 0))
```

This correlation plot shows the correlation between pairs of the predictors in our dataset. 
From a high-level perspective darker blue and darker red circles indicate high positive and high negative correlations, 
respectively. 

Nonetheless, there are a few pairs of variables that are highly correlated:














